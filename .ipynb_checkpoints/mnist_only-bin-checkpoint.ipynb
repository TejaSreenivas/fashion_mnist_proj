{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import load_mnist\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.9.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cnn_model import model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_image(x):\n",
    "    x = np.transpose(x,[0,2,3,1])\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_two_hot(targets, nb_classes):\n",
    "    res = np.hstack((np.eye(nb_classes,dtype=np.float32),-1*np.eye(nb_classes,dtype=np.float32)))[np.array(targets).reshape(-1)]\n",
    "    return res.reshape(list(targets.shape)+[2*nb_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 1, 28, 28), (10000, 1, 28, 28))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist = dict()\n",
    "mnist['train_x'],mnist['train_y'],mnist['test_x'],mnist['test_y'] = load_mnist.load_mnist_dataset(os.getcwd()+\"/mnist\")\n",
    "mnist['train_x'].shape,mnist['test_x'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist['train_x'] = reshape_image(mnist['train_x']/255)\n",
    "mnist['test_x'] = reshape_image(mnist['test_x']/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist['test_y'] = get_two_hot(mnist['test_y'],10)\n",
    "mnist['train_y'] = get_two_hot(mnist['train_y'],10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28, 1), (10000, 28, 28, 1))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist['train_x'].shape,mnist['test_x'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<BatchDataset shapes: ((?, 28, 28, 1), (?, 20)), types: (tf.float32, tf.float32)>,\n",
       " <BatchDataset shapes: ((?, 28, 28, 1), (?, 20)), types: (tf.float32, tf.float32)>,\n",
       " <BatchDataset shapes: ((?, 28, 28, 1), (?, 20)), types: (tf.float32, tf.float32)>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train\n",
    "dtrain_x = tf.data.Dataset.from_tensor_slices(mnist['train_x'])\n",
    "dtrain_y = tf.data.Dataset.from_tensor_slices(mnist['train_y'])\n",
    "train_data = tf.data.Dataset.zip((dtrain_x,dtrain_y)).shuffle(500).repeat().batch(batch_size)\n",
    "\n",
    "train_one_shot = tf.data.Dataset.zip((dtrain_x,dtrain_y)).batch(batch_size)\n",
    "\n",
    "dtest_x = tf.data.Dataset.from_tensor_slices(mnist['test_x'])\n",
    "dtest_y = tf.data.Dataset.from_tensor_slices(mnist['test_y'])\n",
    "test_data = tf.data.Dataset.zip((dtest_x,dtest_y)).batch(batch_size)\n",
    "\n",
    "dvalid_x = tf.data.Dataset.from_tensor_slices(mnist['test_x'][:1001])\n",
    "dvalid_y = tf.data.Dataset.from_tensor_slices(mnist['test_y'][:1001])\n",
    "valid_data =  tf.data.Dataset.zip((dvalid_x,dvalid_y)).repeat().batch(batch_size)\n",
    "\n",
    "(train_data,test_data,valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data pipline iterator initializer\n",
    "iterator = tf.data.Iterator.from_structure(train_data.output_types,train_data.output_shapes)\n",
    "get_batch = iterator.get_next()\n",
    "#train data 1 shot\n",
    "train_1s_init = iterator.make_initializer(train_one_shot)\n",
    "\n",
    "#train data initiallizer shuffled\n",
    "train_init = iterator.make_initializer(train_data)\n",
    "#test data initializer shuffled\n",
    "test_init = iterator.make_initializer(test_data)\n",
    "# test data one shot initializer\n",
    "valid_init = iterator.make_initializer(valid_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param=[]\n",
    "param.append(1)\n",
    "param.append([5,64])\n",
    "param.append([5,64])\n",
    "param.append(1000)\n",
    "param.append(20)\n",
    "len(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_train = tf.placeholder(shape=(),dtype=tf.bool)\n",
    "prob_keep = tf.placeholder(shape=(),dtype=tf.float32)\n",
    "cnn = model(get_batch[0],is_train,prob_keep,param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "varname : conv_1/weight:0 [Dimension(5), Dimension(5), Dimension(1), Dimension(64)]\n",
      "varname : conv_1/bias:0 [Dimension(64)]\n",
      "varname : conv_2/weight:0 [Dimension(5), Dimension(5), Dimension(64), Dimension(64)]\n",
      "varname : conv_2/bias:0 [Dimension(64)]\n",
      "varname : dense/kernel:0 [Dimension(3136), Dimension(1000)]\n",
      "varname : dense/bias:0 [Dimension(1000)]\n",
      "varname : dense_1/kernel:0 [Dimension(1000), Dimension(20)]\n",
      "varname : dense_1/bias:0 [Dimension(20)]\n",
      "total number of trainable parameter : 3261148\n"
     ]
    }
   ],
   "source": [
    "logits = cnn.logits\n",
    "info = cnn.total_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=get_batch[1],logits=logits))\n",
    "\n",
    "tf.summary.scalar(\"losses\",loss)\n",
    "optimizer = tf.train.AdamOptimizer(0.001).minimize(loss)\n",
    "#confusion matrix\n",
    "conf_mtx = tf.confusion_matrix(labels=tf.argmax(get_batch[1],axis=1),predictions = tf.argmax(logits,axis=1),num_classes=10)\n",
    "#get accuracy\n",
    "predictions = tf.argmax(logits,axis=1)\n",
    "equality = tf.equal(predictions,tf.argmax(get_batch[1],axis=1))\n",
    "accuracy = tf.reduce_mean(tf.cast(equality,tf.float32))\n",
    "tf.summary.scalar(\"accuracy\",accuracy)\n",
    "init_op = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/output/logs_mnist\n"
     ]
    }
   ],
   "source": [
    "log_dir = '/output/logs_mnist'\n",
    "print(log_dir)\n",
    "t_summary = tf.summary.merge_all()\n",
    "writer = tf.summary.FileWriter(log_dir)\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "epochs = int(epochs*60000/(batch_size))\n",
    "probability_keep = 0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-51240d494bd9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_init\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0macc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mt_summary\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mis_train\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mprob_keep\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mprobability_keep\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m         \u001b[0mduration\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mduration\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    898\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 900\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    901\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1135\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1136\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1314\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1316\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1317\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1320\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1322\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1323\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1307\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1309\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1409\u001b[1;33m           run_metadata)\n\u001b[0m\u001b[0;32m   1410\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1411\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "duration = 0\n",
    "confusion_matrix = np.zeros((10,10),dtype=np.int32)\n",
    "with tf.Session() as sess:\n",
    "    #saver.restore(sess,log_dir+'/curr_model.ckpt')\n",
    "    writer.add_graph(sess.graph)\n",
    "    sess.run(init_op)\n",
    "    train_log_loss=[]\n",
    "    valid_log_acc =[]\n",
    "    for i in range(1,epochs+1):\n",
    "        sess.run(train_init)\n",
    "        start_time = time.time()\n",
    "        l,_,acc,s = sess.run([loss,optimizer,accuracy,t_summary],feed_dict={is_train:True,prob_keep:probability_keep})\n",
    "        duration = duration + time.time() - start_time\n",
    "        \n",
    "        writer.add_summary(s,i)\n",
    "        # history of loss and accuracy while training\n",
    "        train_log_loss.append(l)\n",
    "        \n",
    "        if i%100==0:\n",
    "            print(\"Epoch :{}, loss :{:.3f}, accuracy :{:.3f}\".format(i,l,acc))\n",
    "            save_path = saver.save(sess,log_dir+'/curr_model.ckpt')    \n",
    "            valid_iter = 10\n",
    "            avg_acc = 0\n",
    "            sess.run(valid_init)\n",
    "            for _ in range(valid_iter):\n",
    "                acc = sess.run([accuracy],feed_dict = {is_train:False,prob_keep:1.0})\n",
    "                avg_acc+=acc[0]\n",
    "            avg_acc=avg_acc*100.0/10\n",
    "            valid_log_acc.append(avg_acc)\n",
    "            print(\"average accuracy :{:.2f}\".format(avg_acc))\n",
    "            \n",
    "        if i>600 and avg_acc>=97.5:\n",
    "            break\n",
    "    \n",
    "    print(\"total training duration : {} sec\".format(duration))\n",
    "    #final accuracy on test data\n",
    "    i=0\n",
    "    test_acc = 0\n",
    "    sess.run(test_init)\n",
    "    while True:\n",
    "        try:\n",
    "            i+=1\n",
    "            #100 --> batch size for one_shot_iter is 100\n",
    "            acc,cfmtx = sess.run([accuracy,conf_mtx],feed_dict = {is_train:False,prob_keep:1.0})\n",
    "            confusion_matrix = confusion_matrix + cfmtx\n",
    "            test_acc+=acc\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            print(\"number of iter  : {}\".format(i))\n",
    "            print(\"Test Accuracy: {}\".format(test_acc/100))\n",
    "            plt.plot(train_log_loss,label='loss_train',color='r')\n",
    "            plt.plot(valid_log_acc,label='acc_train',color='b')\n",
    "            plt.xlabel(\"epochs\")\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "            break\n",
    "    train_acc = 0\n",
    "    i = 0\n",
    "    sess.run(train_1s_init)\n",
    "    while True:\n",
    "        try:\n",
    "            acc = sess.run([accuracy],feed_dict = {is_train:False,prob_keep:1.0})\n",
    "            i+=1\n",
    "            train_acc+=acc[0]\n",
    "        except:\n",
    "            train_acc = train_acc*100/i\n",
    "            print(\"train accuracy : {:.3}\".format(train_acc))\n",
    "            break                \n",
    "                  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_dict = dict()\n",
    "mnist_dict['confusion_matrix'] = confusion_matrix\n",
    "mnist_dict['batch_size'] = batch_size\n",
    "mnist_dict['epochs'] = epochs\n",
    "mnist_dict['param_info'] = info\n",
    "mnist_dict['duration'] = np.array([duration])\n",
    "mnist_dict['loss'] = np.array(train_log_loss)\n",
    "mnist_dict['accuracy'] = np.array(valid_log_acc)\n",
    "mnist_dict['test_accuracy'] = np.array(test_acc)\n",
    "mnist_dict['train_accuracy'] = np.array(train_acc)\n",
    "np.save('/floyd/home/mnist_bin_logs_5e.npy',mnist_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_dict['confusion_matrix']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
