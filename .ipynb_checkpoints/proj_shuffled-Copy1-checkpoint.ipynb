{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import load_mnist\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt \n",
    "from cnn_model import model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_image(x):\n",
    "    x = np.transpose(x,[0,2,3,1])\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fashion_label_change(x):\n",
    "    for i in range(x.shape[0]):\n",
    "        x[i]+=10\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion = dict()\n",
    "mnist = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion['train_x'],fashion['train_y'],fashion['test_x'],fashion['test_y'] = load_mnist.load_mnist_dataset(os.getcwd()+\"/fashion\")\n",
    "mnist['train_x'],mnist['train_y'],mnist['test_x'],mnist['test_y'] = load_mnist.load_mnist_dataset(os.getcwd()+\"/mnist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 1, 28, 28),\n",
       " (10000, 1, 28, 28),\n",
       " (60000, 1, 28, 28),\n",
       " (10000, 1, 28, 28))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fashion['train_x'].shape,fashion['test_x'].shape,mnist['train_x'].shape,mnist['test_x'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAFAlJREFUeJzt3X2MXOV1BvDnzOzsjndtr9f22vhjG2MwbikQEzbmUxWpCyJNFEhTEK6CnAhhIoWoKOkHclXBH42EqpCUpk0iJ1gxakJCBBQLEAXcRiSIujbUhK+kfHQDy5q1vYvt9cd4Z2dO/9gxXWDvOcPcuffO+n1+kuXdOXtn3p2ZZ2d2z33fV1QVRBSeXNYDIKJsMPxEgWL4iQLF8BMFiuEnChTDTxQohp8oUAw/UaAYfqJAtaV5Y+3SoUV0pXmTM0PXLLN8vFfMuuSrkTUt2z/fZcK+bo8W7DNEZxXHI2uLC4fMYwcO9Jr1jsEjZj1EJRzBuB6v60GNFX4RuQLAnQDyAH6gqrdbX19EF86XdXFuMjni3F8Jngataz5q1l+5wX6YZs05Hlk7tr/TPLb4tn3d6twtx5eUzfrZq9+MrH11+WPmsdc/uNGsn/7V/zTricrw+WLZodvr/tqG3/aLSB7APwP4JIAzAawXkTMbvT4iSlec3/nXAnhVVV9X1XEAPwFwZXOGRURJixP+ZQCmvqcbrF32HiKyUUR2iciuMqLfnhJRuuKEf7pfej7wi46qblbVflXtL6Ajxs0RUTPFCf8ggL4pny8HMBRvOESUljjh3wlglYicKiLtAK4FsK05wyKipDXc6lPVCRG5CcC/YbLVt0VVX2zayD6suK2XGK2ZV/7pfLP+s09926xXsLPh2waA50t9kbXeNruX/t9HV8S67bNmDZr1vsJIZG1lW/Q5AADw2Oe+YdZPu3a2Wf+z//1EZO3tW1eaxxaeeMasu8+XXN6uVyt2PQWx+vyq+giAR5o0FiJKEU/vJQoUw08UKIafKFAMP1GgGH6iQDH8RIGSNHfsmSvztVWn9I5cf6FZv+kv74us/VHn6+axL433mPWq8zP4ULVo1i8ovhVZ+7nTx/+7+6826xNd9vPjZ5/5R7N+Xkd7ZO3nx+J933NzJbPe55zjYLn+N583651/OmrWK4cav+04duh2HNLRuubz85WfKFAMP1GgGH6iQDH8RIFi+IkCxfATBWpmtfqsabvO93Hkc/a02+/ccadZ31eJXnJ838Rc89h5+aNmvaQFsz4nd8ysvz0xz7hte3nrAuyppaMVe9rs0sI7Zr1Ujf7ejqq9stO8nH2/eQ5Uo1curqj9undR0V6X5tsjF5n1Z87N5nWVrT4icjH8RIFi+IkCxfATBYrhJwoUw08UKIafKFCpbtEdW4xzEtpuHDbrVWc72ji99KLYO9nmEL3FNuCfB9Cbb3z6aF7s2/aW/vbOA7D66V05e/u2cbWXv/amQndK9PVXxT72kSOnm/UvzH/arD/6pb8w673fs49PA1/5iQLF8BMFiuEnChTDTxQohp8oUAw/UaAYfqJAxerzi8gAgDEAFQATqtrfjEEl4Ssr/t2sv1XpNutWr96bG35I7SWovV67pwxnO2jD0ao9p97jnaOQM763CuxzKyoxvi/veO8xW9B22KyXnHMQFl3zhlnX75nlVDTjJJ9PqOr+JlwPEaWIb/uJAhU3/ArgMRF5RkQ2NmNARJSOuG/7L1bVIRFZBOBxEfm1qj459QtqPxQ2AkAR0WuqEVG6Yr3yq+pQ7f+9AB4AsHaar9msqv2q2l9AvD8uEVHzNBx+EekSkTknPgZwOYAXmjUwIkpWnLf9iwE8IJPLabcB+LGqPtqUURFR4hoOv6q+DuCjTRxLLEf/xF6X/+yOp8z67uNLzbrV5/d65QWx18YHJpx6crw+/UyWR/T6D+WYf+u29nEAgK+f+oBZ3/TB35BTx1YfUaAYfqJAMfxEgWL4iQLF8BMFiuEnCtTMWrrbMHi5vax32ZnC6bGWmfZbfdm18rzlrbNs9XnTauOO3WrnecuCe9uDH3BafS+Vlpv1VsBXfqJAMfxEgWL4iQLF8BMFiuEnChTDTxQohp8oUCdNn3/1GW+Z9bFqu1kvq31XLDD6viNib1Pt9as9Xj/cUnb62dbS2oA9LRaIv+x4HHHu13Z3mnU8X+n5rVl/CD2J3n49+MpPFCiGnyhQDD9RoBh+okAx/ESBYviJAsXwEwXqpOnzL5o1ltlte3O/91Xm2sfnj5j1itrnKFi8Pn5c3jkIWZ4HYI1tQd7egtvbPtw7f6KsyZ5H0Ax85ScKFMNPFCiGnyhQDD9RoBh+okAx/ESBYviJAuX2+UVkC4BPA9irqmfVLpsP4KcAVgAYAHCNqr6T3DB9f9jza7Ne0oJZr6jd1y0Z8/2XtR0yj32zvMCsl3P2w+D1nKtGP7vi/HzPe+v2x5zvH2ctgris+807/+FItRjrtgtinweQXxj9nKjsH4l12/Wq55H5IYAr3nfZLQC2q+oqANtrnxPRDOKGX1WfBDD6vouvBLC19vFWAFc1eVxElLBG35MtVtU9AFD7f1HzhkREaUj83H4R2QhgIwAU0Zn0zRFRnRp95R8WkSUAUPt/b9QXqupmVe1X1f4C7A0tiSg9jYZ/G4ANtY83AHiwOcMhorS44ReRewA8DWC1iAyKyPUAbgdwmYi8AuCy2udENIO4v/Or6vqI0romjyWWszsGzfqB6iyznhe7Xz1Sjd6PfXnbMfPYgkyYdW+v+DjcPn5M3jkI3nkASbLOfyhK2Tz27Wq3WY/7mOnyxdHFFurzE9FJiOEnChTDTxQohp8oUAw/UaAYfqJAnTRLd8/J2a2bkUp0q64eJWOL7968feZi0Rmb1ZIC/OmnSS/PHYfXCrR4bUJv+eyCsQ13e8wWqNca9hxbGv187Ngd66rrxld+okAx/ESBYviJAsXwEwWK4ScKFMNPFCiGnyhQJ02fvzdn95NfQXLTZocrx826169u3S59srzzG7ry9lTpsQl763Orzz9StZeUazeObYZST/TzMa31rvjKTxQohp8oUAw/UaAYfqJAMfxEgWL4iQLF8BMF6qTp8/fk7b5t2dhiG/CX17bsq0TP9QeAvDPf3puXHne+f6vyxu1t792Zs8+vGCr3RNaKuXHzWG9pbu8x8RzrjT7eXjS8efjKTxQohp8oUAw/UaAYfqJAMfxEgWL4iQLF8BMFyu3zi8gWAJ8GsFdVz6pddhuAGwDsq33ZJlV9JKlBnpDvie7bekrVgln31ta3+r4Fp1/tbQddQryxWf3wpLfQjnP93vkNZefp6d2voxPRa+P3tdvXPTdXMut7J+aY9ePqPJ/mmeVU1PPK/0MAV0xz+bdUdU3tX+LBJ6LmcsOvqk8CGE1hLESUoji/898kIr8SkS0i0vj7cSLKRKPh/y6A0wCsAbAHwB1RXygiG0Vkl4jsKsM+F5uI0tNQ+FV1WFUrqloF8H0Aa42v3ayq/araX0htaUIi8jQUfhFZMuXTzwJ4oTnDIaK01NPquwfApQAWisgggFsBXCoiawAogAEANyY4RiJKgBt+VV0/zcV3JTAWV3Xl0oaPrThvcpa2vWPW/2Xkoshae7e9xvsp+YNm/VC1aNZzzsr+1vcWt4/v8a7fWsugpPb5Dd7Qu5z5/AsLY5G1v33hM+axD5+32ay/Nr7IrA9N2GMb785+DQae4UcUKIafKFAMP1GgGH6iQDH8RIFi+IkCNaOW7j62NHqK5n8d96a92lNPV7bZSzk/9OLZkbUzPz5kHntm+7BZHyjbP4OrMnN/RlvTjefk7C24vVbggYq9XHtv26HI2uER+9hOsZ8v1nUDQMlZ2lsX2M+3NMzcZxURxcLwEwWK4ScKFMNPFCiGnyhQDD9RoBh+okDNqD7/0d7opZ67nC22vS26F+ajzyEAgNnPGdNuP24eioIzN9XbDroI+xyGmcp7TLylucd0llnvaxuJrOXG7NvuydnX3S72NO6jzvfW3X3UrKeBr/xEgWL4iQLF8BMFiuEnChTDTxQohp8oUAw/UaBmVJ//2CJ7jrXFW7rb0z0Q3dftbYteIhrw53bPzdvbQReccxish9E7hyDppb0t3hbd1rLfAJB3ljTvzUevF1DcZz8mx9Seb+89Jt79erycffT4yk8UKIafKFAMP1GgGH6iQDH8RIFi+IkCxfATBcptNopIH4C7AZwCoApgs6reKSLzAfwUwAoAAwCuUVV7n+uYxruje6dlp5fe7vbKbcWR6L7vMmd77zFn/XlvC26vZ1wxjs/H/Pnu9dqzvO6cc/xH2toja73P2WsFjFbt54u1HwEA5MR+zCbK9jkOaajnmTEB4Guq+nsALgDwZRE5E8AtALar6ioA22ufE9EM4YZfVfeo6rO1j8cAvAxgGYArAWytfdlWAFclNUgiar4P9Z5QRFYAOBfADgCLVXUPMPkDAsCiZg+OiJJTd/hFZDaA+wDcrKr2RmXvPW6jiOwSkV1lHG9kjESUgLrCLyIFTAb/R6p6f+3iYRFZUqsvAbB3umNVdbOq9qtqfwEdzRgzETWBG34REQB3AXhZVb85pbQNwIbaxxsAPNj84RFRUuqZV3gxgOsAPC8iu2uXbQJwO4B7ReR6AG8AuDqZIf6/ck/0tNoK7Om+3jLQnvbXpn1jAwBYXbB/nXmpbCz7Db/l5X1v9vF2y6qa8Kke/nRk41jYy2PnYLdQOyS63vHwTvPYsjPTeV7eXnq76mwJn8sn10Ktlxt+Vf0lEPnsW9fc4RBRWniGH1GgGH6iQDH8RIFi+IkCxfATBYrhJwpU9usHfwiF7uh+utcL78zZvfj9lSNmfWLo7chaT77TPLY0Hm/5bO97s3hbSVvTgQF/6qp3nsC8XHQ/fNvBj5nHPjW80qz/1WmPmnVLfuECs7796Blm/ZyON836wIR9/eqcB5AGvvITBYrhJwoUw08UKIafKFAMP1GgGH6iQDH8RIGaUX3+ObOjt1wuOctje/P5hyrOUspVu19u8Xrlcfr4gH2egLtFt7cNdsxtso9Uo1dvunD2q+axZxSjz60AgLLGePpO2OsMFMXeojvuY9Y1K/sl7fjKTxQohp8oUAw/UaAYfqJAMfxEgWL4iQLF8BMFakb1+VfN35/YdZ/Tbq+tb/HWAijDntvtnQcQq5/t8Nanj+uI0Q/3zr2Yk48+rwMARiqzzfpTpQORNZnXbR77i4Orzfo5i94y6yPeOgnV7F93sx8BEWWC4ScKFMNPFCiGnyhQDD9RoBh+okAx/ESBchvIItIH4G4ApwCoAtisqneKyG0AbgCwr/alm1T1kaQGCgC7n/jdyFr+uifMYxflD5v1VXffbNZX4unI2sJ8l3nsJcV3zPpg41vYAwBKxpz9sjOf35Nz5vN7rLUGvDnxXWLfMd7xp7dFv7ZVu+3H7LW/6TXruR9sN+vefgbjz/aY9TTUc/bIBICvqeqzIjIHwDMi8nit9i1V/UZywyOipLjhV9U9APbUPh4TkZcBLEt6YESUrA/1O7+IrABwLoAdtYtuEpFficgWEZn2fYyIbBSRXSKyq4zsly4iokl1h19EZgO4D8DNqnoIwHcBnAZgDSbfGdwx3XGqullV+1W1v4Do9dyIKF11hV9ECpgM/o9U9X4AUNVhVa2oahXA9wGsTW6YRNRsbvhFRADcBeBlVf3mlMuXTPmyzwJ4ofnDI6Kk1PPX/osBXAfgeRHZXbtsE4D1IrIGgAIYAHBjIiOc4pQd0VNA+74YvRU0AHSK3RZa+lTjS3NffPOXzPrBa8fMenenPXX1U0tfNOtL26Nbid50YU/FeX3wWolV4/bHKvY06oeHft++bWe59YmHFkbWep+Lbt0CgKw7z6wXnCm7lxSHzXrplJj93Sao56/9vwSmbagm2tMnomTxDD+iQDH8RIFi+IkCxfATBYrhJwoUw08UKFFNeO3mKebKfD1f1iVy3aNfvNCse+3uBXfZfV+iqQ5+/gKzfnSx/YTru/eNyNrEm4MNjQkAduh2HNLRuvYP5ys/UaAYfqJAMfxEgWL4iQLF8BMFiuEnChTDTxSoVPv8IrIPwG+nXLQQQHL7bsfTqmNr1XEBHFujmjm2j6iqve54Tarh/8CNi+xS1f7MBmBo1bG16rgAjq1RWY2Nb/uJAsXwEwUq6/Bvzvj2La06tlYdF8CxNSqTsWX6Oz8RZSfrV34iykgm4ReRK0TkNyLyqojcksUYoojIgIg8LyK7RWRXxmPZIiJ7ReSFKZfNF5HHReSV2v+ZbPcaMbbbROSt2n23W0T+OKOx9YnIf4jIyyLyooj8ee3yTO87Y1yZ3G+pv+0XkTyA/wFwGYBBADsBrFfVl1IdSAQRGQDQr6qZ94RF5A8AHAZwt6qeVbvs7wGMqurttR+cPar61y0yttsAHM565+bahjJLpu4sDeAqAF9AhvedMa5rkMH9lsUr/1oAr6rq66o6DuAnAK7MYBwtT1WfBDD6vouvBLC19vFWTD55UhcxtpagqntU9dnax2MATuwsnel9Z4wrE1mEfxmAN6d8PojW2vJbATwmIs+IyMasBzONxbVt009sn74o4/G8n7tzc5ret7N0y9x3jex43WxZhH+6JYZaqeVwsap+DMAnAXy59vaW6lPXzs1pmWZn6ZbQ6I7XzZZF+AcB9E35fDmAoQzGMS1VHar9vxfAA2i93YeHT2ySWvt/b8bjeVcr7dw83c7SaIH7rpV2vM4i/DsBrBKRU0WkHcC1ALZlMI4PEJGu2h9iICJdAC5H6+0+vA3AhtrHGwA8mOFY3qNVdm6O2lkaGd93rbbjdSYn+dRaGf8AIA9gi6p+PfVBTENEVmLy1R6Y3MT0x1mOTUTuAXApJmd9DQO4FcC/ArgXwO8AeAPA1aqa+h/eIsZ2KSbfur67c/OJ37FTHtslAH4B4Hng3e10N2Hy9+vM7jtjXOuRwf3GM/yIAsUz/IgCxfATBYrhJwoUw08UKIafKFAMP1GgGH6iQDH8RIH6PyoV6tIJumgdAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(fashion['train_x'][np.random.randint(1000),:,:,:].reshape(28,28))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion['train_x'] = reshape_image(fashion['train_x'])\n",
    "fashion['test_x'] = reshape_image(fashion['test_x'])\n",
    "mnist['train_x'] = reshape_image(mnist['train_x'])\n",
    "mnist['test_x'] = reshape_image(mnist['test_x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28, 1),\n",
       " (10000, 28, 28, 1),\n",
       " (60000, 28, 28, 1),\n",
       " (10000, 28, 28, 1))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fashion['train_x'].shape,fashion['test_x'].shape,mnist['train_x'].shape,mnist['test_x'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000,), (10000,), (60000,), (10000,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fashion['train_y'].shape,fashion['test_y'].shape,mnist['train_y'].shape,mnist['test_y'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### label change for all fashion data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion['train_y'] = fashion_label_change(fashion['train_y'])\n",
    "fashion['test_y'] = fashion_label_change(fashion['test_y'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 10\n",
      "19 10\n"
     ]
    }
   ],
   "source": [
    "print(np.max(fashion['test_y']),np.min(fashion['test_y']))\n",
    "print(np.max(fashion['train_y']),np.min(fashion['train_y']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120000, 28, 28, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.vstack((mnist['train_x'],fashion['train_x'])).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.hstack((mnist['test_y'],fashion['test_y'])).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fashion \n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "label  - description\n",
    "| --- | --- |\n",
    "| 10 | T-shirt/top |\n",
    "| 11 | Trouser |\n",
    "| 12 | Pullover |\n",
    "| 13 | Dress |\n",
    "| 14 | Coat |\n",
    "| 15 | Sandal |\n",
    "| 16 | Shirt |\n",
    "| 17 | Sneaker |\n",
    "| 18 | Bag |\n",
    "| 19 | Ankle boot |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {10:'T-shirt/top',11:'Trouser',12:'Pullover',13:'Dress',14:'Coat',15:'Sandal',16:'Shirt',17:'Sneaker',18:'Bag',19:'Ankle boot'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    labels[i] = str(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{10: 'T-shirt/top',\n",
       " 11: 'Trouser',\n",
       " 12: 'Pullover',\n",
       " 13: 'Dress',\n",
       " 14: 'Coat',\n",
       " 15: 'Sandal',\n",
       " 16: 'Shirt',\n",
       " 17: 'Sneaker',\n",
       " 18: 'Bag',\n",
       " 19: 'Ankle boot',\n",
       " 0: '0',\n",
       " 1: '1',\n",
       " 2: '2',\n",
       " 3: '3',\n",
       " 4: '4',\n",
       " 5: '5',\n",
       " 6: '6',\n",
       " 7: '7',\n",
       " 8: '8',\n",
       " 9: '9'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train and test for cummulative dataset (shuffled) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<BatchDataset shapes: ((?, 28, 28, 1), (?, 20)), types: (tf.float32, tf.float32)>,\n",
       " <BatchDataset shapes: ((?, 28, 28, 1), (?, 20)), types: (tf.float32, tf.float32)>,\n",
       " <BatchDataset shapes: ((?, 28, 28, 1), (?, 20)), types: (tf.float32, tf.float32)>,\n",
       " <BatchDataset shapes: ((?, 28, 28, 1), (?, 20)), types: (tf.float32, tf.float32)>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train\n",
    "dtrain_x = tf.data.Dataset.from_tensor_slices(np.vstack((mnist['train_x'],fashion['train_x'])))\n",
    "dtrain_y = tf.data.Dataset.from_tensor_slices(np.hstack((mnist['train_y'],fashion['train_y']))).map(lambda x: tf.one_hot(x,20))\n",
    "train_data = tf.data.Dataset.zip((dtrain_x,dtrain_y)).shuffle(120000).repeat().batch(batch_size)\n",
    "#test\n",
    "dtest_x = tf.data.Dataset.from_tensor_slices(np.vstack((mnist['test_x'],fashion['test_x'])))\n",
    "dtest_y = tf.data.Dataset.from_tensor_slices(np.hstack((mnist['test_y'],fashion['test_y']))).map(lambda x: tf.one_hot(x,20))\n",
    "test_data = tf.data.Dataset.zip((dtest_x,dtest_y)).batch(batch_size)\n",
    "#valid mnist\n",
    "dvalid_mnist_x = tf.data.Dataset.from_tensor_slices(mnist['test_x'][:1001])\n",
    "dvalid_mnist_y = tf.data.Dataset.from_tensor_slices(mnist['test_y'][:1001]).map(lambda x: tf.one_hot(x,20))\n",
    "valid_mnist_data =  tf.data.Dataset.zip((dvalid_mnist_x,dvalid_mnist_y)).repeat().batch(batch_size)\n",
    "#valid fashion\n",
    "dvalid_fashion_x = tf.data.Dataset.from_tensor_slices(fashion['test_x'][:1001])\n",
    "dvalid_fashion_y = tf.data.Dataset.from_tensor_slices(fashion['test_y'][:1001]).map(lambda x: tf.one_hot(x,20))\n",
    "valid_fashion_data =  tf.data.Dataset.zip((dvalid_fashion_x,dvalid_fashion_y)).repeat().batch(batch_size)\n",
    "\n",
    "(train_data,test_data,valid_mnist_data,valid_fashion_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### individual test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mnist train\n",
    "mnist_train_x = tf.data.Dataset.from_tensor_slices(mnist['train_x'])\n",
    "mnist_train_y = tf.data.Dataset.from_tensor_slices(mnist['train_y']).map(lambda x: tf.one_hot(x,20))\n",
    "mnist_train = tf.data.Dataset.zip((mnist_train_x,mnist_train_y)).batch(batch_size)\n",
    "#mnist test\n",
    "mnist_test_x = tf.data.Dataset.from_tensor_slices(mnist['test_x'])\n",
    "mnist_test_y = tf.data.Dataset.from_tensor_slices(mnist['test_y']).map(lambda x: tf.one_hot(x,20))\n",
    "mnist_test = tf.data.Dataset.zip((mnist_test_x,mnist_test_y)).batch(batch_size)\n",
    "#fashion train\n",
    "fashion_train_x = tf.data.Dataset.from_tensor_slices(fashion['train_x'])\n",
    "fashion_train_y = tf.data.Dataset.from_tensor_slices(fashion['train_y']).map(lambda x: tf.one_hot(x,20))\n",
    "fashion_train = tf.data.Dataset.zip((fashion_train_x,fashion_train_y)).batch(batch_size)\n",
    "#fashion test\n",
    "fashion_test_x = tf.data.Dataset.from_tensor_slices(fashion['test_x'])\n",
    "fashion_test_y = tf.data.Dataset.from_tensor_slices(fashion['test_y']).map(lambda x: tf.one_hot(x,20))\n",
    "fashion_test =tf.data.Dataset.zip((fashion_test_x,fashion_test_y)).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data pipline iterator initializer\n",
    "iterator = tf.data.Iterator.from_structure(train_data.output_types,train_data.output_shapes)\n",
    "get_batch = iterator.get_next()\n",
    "\n",
    "#train data initiallizer shuffled\n",
    "train_init = iterator.make_initializer(train_data)\n",
    "#test data initializer shuffled\n",
    "test_init = iterator.make_initializer(test_data)\n",
    "# valid data mnist\n",
    "valid_mnist_init = iterator.make_initializer(valid_mnist_data)\n",
    "# valid data fashion\n",
    "valid_fashion_init = iterator.make_initializer(valid_fashion_data)\n",
    "#fashoin train data initializer\n",
    "fashion_train_init = iterator.make_initializer(fashion_train)\n",
    "# fashion test data initializer \n",
    "fashion_test_init = iterator.make_initializer(fashion_test)\n",
    "#mnist train data initializer\n",
    "mnist_train_init = iterator.make_initializer(mnist_train)\n",
    "#mnist test data initializer\n",
    "mnist_test_init = iterator.make_initializer(mnist_test)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "param:\n",
    "param[0]  -  channel\n",
    "param[1]  -  filter1_size,# filters\n",
    "param[2]  -  filter2_size,# filters\n",
    "param[3]  -  dense size\n",
    "param[4]  -  output_size\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "param=[]\n",
    "param.append(1)\n",
    "param.append([3,64])\n",
    "param.append([3,64])\n",
    "param.append(1000)\n",
    "param.append(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_train = tf.placeholder(shape=(),dtype=tf.bool)\n",
    "prob_keep = tf.placeholder(shape=(),dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = model(get_batch[0],is_train,prob_keep,param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "varname : conv_1/weight:0 [Dimension(3), Dimension(3), Dimension(1), Dimension(64)]\n",
      "varname : conv_1/bias:0 [Dimension(64)]\n",
      "varname : conv_2/weight:0 [Dimension(3), Dimension(3), Dimension(64), Dimension(64)]\n",
      "varname : conv_2/bias:0 [Dimension(64)]\n",
      "varname : dense/kernel:0 [Dimension(3136), Dimension(1000)]\n",
      "varname : dense/bias:0 [Dimension(1000)]\n",
      "varname : dense_1/kernel:0 [Dimension(1000), Dimension(20)]\n",
      "varname : dense_1/bias:0 [Dimension(20)]\n",
      "total number of trainable parameter : 3194588\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'varname : conv_1/weight:0-( 3 3 1 64 )$varname : conv_1/bias:0-( 64 )$varname : conv_2/weight:0-( 3 3 64 64 )$varname : conv_2/bias:0-( 64 )$varname : dense/kernel:0-( 3136 1000 )$varname : dense/bias:0-( 1000 )$varname : dense_1/kernel:0-( 1000 20 )$varname : dense_1/bias:0-( 20 )$total param count : 3194588'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = cnn.logits\n",
    "cnn.total_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'dense_1/BiasAdd:0' shape=(?, 20) dtype=float32>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=get_batch[1],logits=logits))\n",
    "\n",
    "tf.summary.scalar(\"losses\",loss)\n",
    "optimizer = tf.train.AdamOptimizer(0.001).minimize(loss)\n",
    "\n",
    "#get accuracy\n",
    "predictions = tf.argmax(logits,axis=1)\n",
    "equality = tf.equal(predictions,tf.argmax(get_batch[1],axis=1))\n",
    "accuracy = tf.reduce_mean(tf.cast(equality,tf.float32))\n",
    "tf.summary.scalar(\"accuracy\",accuracy)\n",
    "init_op = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output/logs\n"
     ]
    }
   ],
   "source": [
    "log_dir = 'output/logs'\n",
    "print(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_summary = tf.summary.merge_all()\n",
    "writer = tf.summary.FileWriter(log_dir)\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1\n",
    "epochs = int(epochs*120000/100)\n",
    "probability_keep = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accu(sess,init):\n",
    "    i=0\n",
    "    t_acc = 0\n",
    "    sess.run(init)\n",
    "    while True:\n",
    "        try:\n",
    "            #100 --> batch size for one_shot_iter is 100\n",
    "            acc = sess.run([accuracy],feed_dict = {is_train:False,prob_keep:1.0})\n",
    "            i+=1\n",
    "            t_acc+=acc[0]\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            t_acc = t_acc*100.0/i\n",
    "            return t_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration = 0\n",
    "log_mnist_test = 0\n",
    "log_fashion_test = 0\n",
    "with tf.Session() as sess:\n",
    "    #saver.restore(sess,log_dir+'/curr_model.ckpt')\n",
    "    writer.add_graph(sess.graph)\n",
    "    sess.run(init_op)\n",
    "    \n",
    "    train_log_loss = []\n",
    "    train_log_mnist_acc = []\n",
    "    train_log_fashion_acc = []\n",
    "    \n",
    "    for i in range(1,epochs+1):\n",
    "        sess.run(train_init)\n",
    "        start_time = time.time()\n",
    "        l,_,acc,s = sess.run([loss,optimizer,accuracy,t_summary],feed_dict={is_train:True,prob_keep:probability_keep})\n",
    "        duration = duration + time.time() - start_time\n",
    "        writer.add_summary(s,i)\n",
    "        # history of loss and accuracy while training\n",
    "        train_log_loss.append(l)\n",
    "        \n",
    "        if i%100==0:\n",
    "            print(\"Epoch :{}, loss :{:.3f}, accuracy :{:.3f}\".format(i,l,acc))\n",
    "            save_path = saver.save(sess,log_dir+'/curr_model.ckpt')\n",
    "            \n",
    "            #mnist accuracy\n",
    "            mnist_avg_acc = 0\n",
    "            mnist_avg_acc=accu(sess,valid_mnist_init)\n",
    "            print(\"validation mnist accuracy :{:.3f}\".format(mnist_avg_acc))\n",
    "            train_log_mnist_acc.append(mnist_avg_acc)\n",
    "            \n",
    "            #fashion accuracy\n",
    "            fashion_avg_acc = 0\n",
    "            fashion_avg_acc=accu(sess,valid_fashion_init)\n",
    "            print(\"validation fashion accuracy :{:.3f}\".format(fashion_avg_acc))\n",
    "            train_log_fashion_acc.append(fashion_avg_acc)\n",
    "    \n",
    "    #total test\n",
    "    total_test_acc = accu(sess,test_init)\n",
    "    print(\"Test Accuracy: {}\".format(total_test_acc))\n",
    "    plt.plot(train_log_loss,label='loss_train',color='r')\n",
    "    plt.plot(train_log_mnist_acc,label='acc_mnist',color='b')\n",
    "    plt.plot(train_log_fashion_acc,label='acc_fashion',color='g')\n",
    "    plt.xlabel(\"epochs\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    #total train accuracy\n",
    "    #total_train_acc = accu(sess,train_1s_init)\n",
    "    #print(\"total train Accuracy: {}\".format(total_train_acc))\n",
    "    \n",
    "    #mnist test\n",
    "    mnist_test_acc = accu(sess,mnist_test_init)\n",
    "    print(\"MNIST Test Accuracy: {}\".format(mnist_test_acc))\n",
    "    \n",
    "    #mnist train\n",
    "    mnist_train_acc = accu(sess,mnist_train_init)\n",
    "    print(\"MNIST train Accuracy: {}\".format(mnist_train_acc))\n",
    "    \n",
    "    #fashion test\n",
    "    fashion_test_acc = accu(sess,fashion_test_init)\n",
    "    print(\"fashion test Accuracy: {}\".format(fashion_test_acc))\n",
    "    \n",
    "    #fashion train\n",
    "    fashion_train_acc = accu(sess,fashion_train_init)\n",
    "    print(\"fashion Train Accuracy: {}\".format(fashion_train_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save log files\n",
    "log=dict()\n",
    "log['duration'] = np.array(duration)\n",
    "log['loss'] = np.array(train_log_loss)\n",
    "log['mnist_valid'] = np.array(train_log_mnist_acc)\n",
    "log['fashion_valid'] = np.array(train_log_fashion_acc)\n",
    "log['mnist_train_test'] = np.array([log_mnist_train,log_mnist_test])\n",
    "log['fashion_train_test'] = np.array([log_fashion_train,log_fashion_test])\n",
    "np.save('output/proj_shuffle.npy',log)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
